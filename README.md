# Automatic Speech Recognition with AudioMNIST
Final project for deep learning
## Abstract
For this project, I trained the a convolutional neural network to classify digits spoken in the AudioMNIST dataset. The result was 45% accuracy after 20 epochs, which could easily be improved by training for more epochs.

## Problem Statement
The goal is to train a neural network that can predict the digit being said in an audio clip in real-time. Ideally this would require using a RNN, where data points can continuously be streamed into the network to produce a prediction.

## Related work
The paper that created the AudioMNIST dataset already includes a neural network architecture that feeds the entire raw audio signal into the network at once, using an architecture similar to an image classifier to predict which digit from 0-9 is being spoken.

You can download the AudioMNIST dataset from the Github repository [here](https://github.com/soerenab/AudioMNIST).

## Methodology

## Experiments/Evaluation

## Results

## Examples

## Video
